# ä¿®æ”¹æ–‡ä»¶ï¼šsrc/data_fetch/index_fetcher.py
# ä¿®æ”¹å†…å®¹ï¼šä½¿ç”¨æ–°çš„é…ç½®ç»“æ„ï¼Œæ”¯æŒå¤åˆæŒ‡æ•°å’Œå¸¦åç¼€çš„ä»£ç 

"""
æŒ‡æ•°æ•°æ®è·å–å™¨
è´Ÿè´£ä»æ•°æ®æºè·å–å„ç±»æŒ‡æ•°çš„å†å²æ•°æ®
"""
import akshare as ak
import pandas as pd
from datetime import datetime, timedelta
import time
import logging
from typing import Dict, List, Optional, Tuple
try:
    import config
    _FETCH_YEARS = getattr(config, 'DEFAULT_FETCH_YEARS', 3)
except Exception:
    _FETCH_YEARS = 3
import numpy as np

logger = logging.getLogger(__name__)


class IndexDataFetcher:
    """æŒ‡æ•°æ•°æ®è·å–å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æŒ‡æ•°æ•°æ®è·å–å™¨"""
        try:
            import config
            self.config = config
        except ImportError:
            logger.error("æ— æ³•å¯¼å…¥configæ¨¡å—")
            self.config = None
        
        logger.info("âœ… æŒ‡æ•°æ•°æ®è·å–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _get_base_index_info(self, index_code: str) -> Tuple[str, str]:
        """
        è·å–åŸºç¡€æŒ‡æ•°ä¿¡æ¯
        
        Args:
            index_code: æŒ‡æ•°ä»£ç ï¼ˆå¯èƒ½å¸¦åç¼€ï¼‰
            
        Returns:
            (æ ‡å‡†åŒ–ä»£ç , æ˜¾ç¤ºåç§°)
        """
        if self.config:
            normalized_code = self.config.normalize_index_code(index_code)
            display_name = self.config.get_benchmark_display_name(normalized_code)
            return normalized_code, display_name
        return index_code, index_code
    
    def fetch_index_data(self, index_code: str, 
                        start_date: Optional[str] = None, 
                        end_date: Optional[str] = None) -> Optional[pd.DataFrame]:
        """
        è·å–å•ä¸ªæŒ‡æ•°çš„æ•°æ®
        
        Args:
            index_code: æŒ‡æ•°ä»£ç ï¼ˆæ”¯æŒå¸¦åç¼€ï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
            end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
            
        Returns:
            DataFrameåŒ…å«æŒ‡æ•°å†å²æ•°æ®ï¼Œå¤±è´¥åˆ™è¿”å›None
        """
        try:
            # æ ‡å‡†åŒ–ä»£ç å’Œè·å–æ˜¾ç¤ºåç§°
            normalized_code, display_name = self._get_base_index_info(index_code)
            
            logger.info(f"ğŸ” æ­£åœ¨è·å–æŒ‡æ•° {normalized_code} ({display_name}) çš„æ•°æ®...")
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºå¤åˆæŒ‡æ•°
            if self.config and self.config.is_composite_index(normalized_code):
                return self.calculate_composite_index(normalized_code, start_date, end_date)
            
            # å¦‚æœä¸æ˜¯å¤åˆæŒ‡æ•°ï¼Œç›´æ¥ä»æ•°æ®æºè·å–
            # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¥æœŸèŒƒå›´ï¼Œé»˜è®¤è·å–æœ€è¿‘ DEFAULT_FETCH_YEARS å¹´çš„æ•°æ®
            if not start_date:
                start_date = (datetime.now() - timedelta(days=365 * _FETCH_YEARS)).strftime('%Y%m%d')
            if not end_date:
                end_date = datetime.now().strftime('%Y%m%d')
            
            index_data = None
            
            # æ ¹æ®æŒ‡æ•°ä»£ç é€‰æ‹©ä¸åŒçš„æ¥å£
            if normalized_code == 'HSI':
                # æ¸¯è‚¡æŒ‡æ•°
                for symbol in ["HSI", "æ’ç”ŸæŒ‡æ•°"]:
                    try:
                        index_data = ak.stock_hk_index_daily_em(symbol=symbol)
                        break
                    except Exception as e:
                        logger.warning(f"ä½¿ç”¨ stock_hk_index_daily_em è·å– {symbol} å¤±è´¥: {e}")

                if index_data is None:
                    logger.error(f"è·å–æ¸¯è‚¡æŒ‡æ•° {normalized_code} æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥")
                    return None
            else:
                # Aè‚¡æŒ‡æ•°
                try:
                    # å°è¯•ä¸»è¦æ¥å£
                    index_data = ak.index_zh_a_hist(symbol=normalized_code, period="daily", 
                                                  start_date=start_date, end_date=end_date)
                except Exception as e:
                    logger.warning(f"ä½¿ç”¨index_zh_a_histè·å–æŒ‡æ•° {normalized_code} å¤±è´¥: {e}")
                    # å°è¯•å¤‡é€‰æ¥å£
                    try:
                        # å°è¯•å¸¦å¸‚åœºåç¼€çš„ä»£ç 
                        if self.config:
                            index_with_suffix = self.config.get_index_with_suffix(normalized_code)
                            if index_with_suffix != normalized_code:
                                # å°è¯•å»æ‰åç¼€çš„æœ€åéƒ¨åˆ†ï¼ˆå¦‚.SH -> shï¼‰
                                market_code = index_with_suffix.split('.')[-1].lower()
                                if market_code == 'sh':
                                    symbol = f"sh{normalized_code}"
                                elif market_code == 'sz':
                                    symbol = f"sz{normalized_code}"
                                else:
                                    symbol = normalized_code
                            else:
                                symbol = normalized_code
                        else:
                            symbol = normalized_code
                        
                        index_data = ak.stock_zh_index_daily_em(symbol=symbol)
                    except Exception as e2:
                        logger.error(f"è·å–Aè‚¡æŒ‡æ•° {normalized_code} æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥: {e2}")
                        return None
            
            if index_data is None or index_data.empty:
                logger.warning(f"âš ï¸ æŒ‡æ•° {normalized_code} æ²¡æœ‰è·å–åˆ°æ•°æ®")
                return None
            
            # æ ‡å‡†åŒ–åˆ—å
            column_mapping = {
                'date': 'date',
                'Datetime': 'date', 
                'æ—¥æœŸ': 'date',
                'æ—¶é—´': 'date',
                'time': 'date',
                'Date': 'date',
                'trade_date': 'date',
                'æ”¶ç›˜': 'close',
                'æ”¶å¸‚': 'close',
                'æ”¶å¸‚ä»·': 'close',
                'close': 'close',
                'Close': 'close',
                'æ”¶ç›˜ä»·': 'close',
                'latest': 'close'
            }
            
            # é‡å‘½åç°æœ‰åˆ—
            rename_dict = {}
            for col in index_data.columns:
                if col in column_mapping:
                    rename_dict[col] = column_mapping[col]
                elif col.lower() in column_mapping:
                    rename_dict[col] = column_mapping[col.lower()]
                elif col in column_mapping.values():  # å¦‚æœå·²ç»æ˜¯æ ‡å‡†åç§°åˆ™è·³è¿‡
                    continue
            
            if rename_dict:
                index_data.rename(columns=rename_dict, inplace=True)
            
            # ç¡®ä¿å¿…é¡»çš„åˆ—å­˜åœ¨
            if 'date' not in index_data.columns or 'close' not in index_data.columns:
                logger.warning(f"âš ï¸ æŒ‡æ•° {normalized_code} è¿”å›åˆ—: {list(index_data.columns)}")
                logger.warning(f"âš ï¸ æŒ‡æ•° {normalized_code} ç¼ºå°‘å¿…è¦åˆ—: date æˆ– close")
                return None
            
            # ç¡®ä¿æ—¥æœŸåˆ—ä¸ºdatetimeç±»å‹
            index_data['date'] = pd.to_datetime(index_data['date'])
            
            # ç­›é€‰æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„æ•°æ®
            index_data = index_data[
                (index_data['date'] >= pd.to_datetime(start_date)) & 
                (index_data['date'] <= pd.to_datetime(end_date))
            ].copy()
            
            if index_data.empty:
                logger.warning(f"âš ï¸ æŒ‡æ•° {normalized_code} åœ¨æŒ‡å®šæ—¥æœŸèŒƒå›´å†…æ²¡æœ‰æ•°æ®")
                return None
            
            # æŒ‰æ—¥æœŸæ’åº
            index_data.sort_values(by='date', inplace=True)
            index_data.reset_index(drop=True, inplace=True)
            
            logger.info(f"âœ… æŒ‡æ•° {normalized_code} æ•°æ®è·å–æˆåŠŸï¼Œå…± {len(index_data)} æ¡è®°å½•")
            
            # æ·»åŠ æŒ‡æ•°ä»£ç åˆ—
            index_data['index_id'] = normalized_code
            
            return index_data
            
        except Exception as e:
            logger.error(f"âŒ è·å–æŒ‡æ•° {index_code} æ•°æ®å¤±è´¥: {e}")
            return None
    
    def calculate_composite_index(self, composite_code: str, 
                                 start_date: Optional[str] = None,
                                 end_date: Optional[str] = None) -> Optional[pd.DataFrame]:
        """
        è®¡ç®—å¤åˆæŒ‡æ•°
        
        Args:
            composite_code: å¤åˆæŒ‡æ•°ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            å¤åˆæŒ‡æ•°çš„DataFrame
        """
        try:
            if not self.config:
                logger.error("æ— æ³•è·å–é…ç½®ä¿¡æ¯")
                return None
            
            # è·å–å¤åˆæŒ‡æ•°é…ç½®
            components = self.config.get_composite_components(composite_code)
            if not components:
                logger.error(f"å¤åˆæŒ‡æ•° {composite_code} æ²¡æœ‰é…ç½®æˆåˆ†")
                return None
            
            logger.info(f"ğŸ”¬ æ­£åœ¨è®¡ç®—å¤åˆæŒ‡æ•° {composite_code}...")
            
            # è·å–æ‰€æœ‰æˆåˆ†æŒ‡æ•°çš„æ•°æ®
            component_data = {}
            for comp in components:
                base_code = comp['base_code']
                weight = comp.get('weight', 1.0)
                
                logger.info(f"  è·å–æˆåˆ† {base_code} (æƒé‡: {weight})...")
                data = self.fetch_index_data(base_code, start_date, end_date)
                
                if data is None or data.empty:
                    logger.warning(f"  æˆåˆ† {base_code} æ•°æ®è·å–å¤±è´¥")
                    continue
                
                component_data[base_code] = {
                    'data': data[['date', 'close']].copy(),
                    'weight': weight
                }
            
            if not component_data:
                logger.error(f"æ— æ³•è·å–å¤åˆæŒ‡æ•° {composite_code} çš„ä»»ä½•æˆåˆ†æ•°æ®")
                return None
            
            # å‡†å¤‡åˆå¹¶æ•°æ®
            all_dates = None
            for code, comp_info in component_data.items():
                if all_dates is None:
                    all_dates = set(comp_info['data']['date'])
                else:
                    all_dates = all_dates.intersection(set(comp_info['data']['date']))
            
            if not all_dates:
                logger.error("æ— æ³•æ‰¾åˆ°æˆåˆ†æŒ‡æ•°çš„å…±åŒæ—¥æœŸ")
                return None
            
            # è½¬æ¢ä¸ºæ’åºçš„æ—¥æœŸåˆ—è¡¨
            all_dates = sorted(list(all_dates))
            
            # åˆ›å»ºç»“æœDataFrame
            result_df = pd.DataFrame({'date': all_dates})
            
            # ä¸ºæ¯ä¸ªæˆåˆ†æ·»åŠ æ”¶ç›Šç‡åˆ—
            for code, comp_info in component_data.items():
                comp_df = comp_info['data']
                # ç­›é€‰å…±åŒæ—¥æœŸ
                comp_df = comp_df[comp_df['date'].isin(all_dates)].copy()
                comp_df.sort_values('date', inplace=True)
                
                # è®¡ç®—æ”¶ç›Šç‡
                comp_df['return'] = comp_df['close'].pct_change()
                
                # åˆå¹¶åˆ°ç»“æœDataFrame
                comp_df = comp_df[['date', 'return']]
                result_df = pd.merge(result_df, comp_df, on='date', how='left', suffixes=('', f'_{code}'))
            
            # è®¡ç®—åŠ æƒå¹³å‡æ”¶ç›Šç‡
            return_columns = [col for col in result_df.columns if col.startswith('return_')]
            
            # ç¡®ä¿æƒé‡å‘é‡ä¸æ”¶ç›Šç‡åˆ—åŒ¹é…
            weights = []
            for col in return_columns:
                code = col.replace('return_', '')
                if code in component_data:
                    weights.append(component_data[code]['weight'])
                else:
                    weights.append(0)
            
            # å½’ä¸€åŒ–æƒé‡
            total_weight = sum(weights)
            if total_weight > 0:
                weights = [w / total_weight for w in weights]
            
            # è®¡ç®—ç»„åˆæ”¶ç›Šç‡
            result_df['portfolio_return'] = 0
            for i, col in enumerate(return_columns):
                result_df['portfolio_return'] += result_df[col] * weights[i]
            
            # ä»æ”¶ç›Šç‡è®¡ç®—å‡€å€¼åºåˆ—ï¼ˆåˆå§‹å‡€å€¼ä¸º1.0ï¼‰
            result_df['close'] = (1 + result_df['portfolio_return']).cumprod()
            
            # æ·»åŠ æŒ‡æ•°ä»£ç 
            result_df['index_id'] = composite_code
            
            # åªä¿ç•™éœ€è¦çš„åˆ—
            result_df = result_df[['date', 'close', 'index_id']].copy()
            
            logger.info(f"âœ… å¤åˆæŒ‡æ•° {composite_code} è®¡ç®—æˆåŠŸï¼Œå…± {len(result_df)} æ¡è®°å½•")
            return result_df
            
        except Exception as e:
            logger.error(f"âŒ è®¡ç®—å¤åˆæŒ‡æ•° {composite_code} å¤±è´¥: {e}")
            return None
    
    def fetch_all_indices_data(self, index_codes: List[str] = None) -> Dict[str, pd.DataFrame]:
        """
        è·å–å¤šä¸ªæŒ‡æ•°çš„æ•°æ®
        
        Args:
            index_codes: æŒ‡æ•°ä»£ç åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®ä¸­çš„åŸºå‡†æŒ‡æ•°
            
        Returns:
            å­—å…¸ï¼Œé”®ä¸ºæŒ‡æ•°ä»£ç ï¼Œå€¼ä¸ºå¯¹åº”çš„DataFrame
        """
        if index_codes is None:
            try:
                index_codes = self.config.get_actual_benchmark_codes()
            except:
                index_codes = ['000001', '000300', 'HSI']
        
        results = {}
        
        for idx_code in index_codes:
            # æ ‡å‡†åŒ–ä»£ç å’Œè·å–æ˜¾ç¤ºåç§°
            normalized_code, display_name = self._get_base_index_info(idx_code)
            
            logger.info(f"ğŸ“Š æ­£åœ¨è·å–æŒ‡æ•° {normalized_code} ({display_name}) çš„æ•°æ®...")
            
            # è·å–å•ä¸ªæŒ‡æ•°æ•°æ®
            index_data = self.fetch_index_data(idx_code)
            
            if index_data is not None:
                results[normalized_code] = index_data
            else:
                logger.warning(f"âš ï¸ æŒ‡æ•° {normalized_code} æ•°æ®è·å–å¤±è´¥")
            
            # æ·»åŠ å»¶æ—¶é¿å…è¿‡äºé¢‘ç¹çš„APIè°ƒç”¨
            time.sleep(0.5)
        
        logger.info(f"âœ… å…±æˆåŠŸè·å– {len(results)} ä¸ªæŒ‡æ•°çš„æ•°æ®")
        return results

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    fetcher = IndexDataFetcher()
    
    # æµ‹è¯•åŸºç¡€æŒ‡æ•°
    test_codes = ['000300.SH', 'HSI.HK', '000001.SH']
    results = fetcher.fetch_all_indices_data(test_codes)
    
    for code, data in results.items():
        print(f"\næŒ‡æ•° {code} çš„å‰5æ¡æ•°æ®:")
        print(data.head())
    
    # æµ‹è¯•å¤åˆæŒ‡æ•°
    print("\n" + "="*50)
    print("æµ‹è¯•åŒ»ç–—åˆ›æ–°æŒ‡æ•°è®¡ç®—:")
    medical_index = fetcher.calculate_composite_index('MED_INNOV')
    if medical_index is not None:
        print(medical_index.head())
    
    # æµ‹è¯•æ–°å¤åˆæŒ‡æ•°
    print("\næµ‹è¯•è‡ªå®šä¹‰å¤åˆæŒ‡æ•°è®¡ç®—:")
    custom_index = fetcher.calculate_composite_index('CUSTOM_COMPOSITE')
    if custom_index is not None:
        print(custom_index.head())