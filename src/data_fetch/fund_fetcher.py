# ä¿®æ”¹æ–‡ä»¶ï¼šsrc/data_fetch/fund_fetcher.py
# ä¿®æ”¹å†…å®¹ï¼šå¢åŠ åŸºé‡‘èµ„äº§è§„æ¨¡æ•°æ®è·å–åŠŸèƒ½

"""
åŸºé‡‘æ•°æ®è·å–å™¨
è´Ÿè´£ä»æ•°æ®æºè·å–åŸºé‡‘çš„å†å²å‡€å€¼ç­‰æ•°æ®
"""
import akshare as ak
import pandas as pd
from datetime import datetime, timedelta
import time
import logging
from typing import Dict, List, Optional, Any
try:
    import config
    _FETCH_YEARS = getattr(config, 'DEFAULT_FETCH_YEARS', 3)
except Exception:
    _FETCH_YEARS = 3

logger = logging.getLogger(__name__)

# ç›´æ¥å¯¼å…¥åŸºé‡‘ä»£ç ç®¡ç†å™¨
try:
    from src.utils.fund_code_manager import fund_code_manager
    logger.info("âœ… æˆåŠŸå¯¼å…¥åŸºé‡‘ä»£ç ç®¡ç†å™¨")
except ImportError as e:
    logger.error(f"âŒ å¯¼å…¥åŸºé‡‘ä»£ç ç®¡ç†å™¨å¤±è´¥: {e}")
    # åˆ›å»ºç®€å•çš„å›é€€æ–¹æ¡ˆ
    class SimpleFundCodeManager:
        @staticmethod
        def to_akshare_format(fund_code: str) -> str:
            return fund_code.replace('.OF', '') if fund_code else ''
        
        @staticmethod
        def to_display_format(fund_code: str) -> str:
            if fund_code.endswith('.OF'):
                return fund_code
            return f"{fund_code}.OF"
        
        @staticmethod
        def batch_to_akshare(fund_codes: List[str]) -> List[str]:
            return [code.replace('.OF', '') for code in fund_codes]
        
        @staticmethod
        def batch_to_display(fund_codes: List[str]) -> List[str]:
            return [code if code.endswith('.OF') else f"{code}.OF" for code in fund_codes]
        
        @staticmethod
        def get_code_pair(fund_code: str) -> dict:
            pure_code = fund_code.replace('.OF', '')
            display_code = fund_code if fund_code.endswith('.OF') else f"{fund_code}.OF"
            return {
                'original': fund_code,
                'akshare': pure_code,
                'display': display_code,
                'database': display_code
            }
    
    fund_code_manager = SimpleFundCodeManager()
    logger.info("âš ï¸ ä½¿ç”¨ç®€å•åŸºé‡‘ä»£ç ç®¡ç†å™¨")


# è¿™äº›ä»£ç ç”¨äºæµ‹è¯•å’Œæ¼”ç¤ºï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦æ›¿æ¢ä¸ºæœ‰æ•ˆçš„åŸºé‡‘ä»£ç 
SAMPLE_FUND_CODES = [
    '161725',  # æ‹›å•†ä¸­è¯ç™½é…’æŒ‡æ•°åˆ†çº§
    '002621',  # ä¸­é‚®è¶‹åŠ¿ä¼˜é€‰çµæ´»é…ç½®æ··åˆA
    '005918',  # å¹¿å‘åŒ»ç–—ä¿å¥è‚¡ç¥¨A
    '003598'   # å—æ–¹å“è´¨ä¼˜é€‰çµæ´»é…ç½®æ··åˆA
]

class FundDataFetcher:
    """åŸºé‡‘æ•°æ®è·å–å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ•°æ®è·å–å™¨"""
        self.fund_codes = []
        self.data_cache = {}
        logger.info("âœ… åŸºé‡‘æ•°æ®è·å–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def set_fund_codes(self, codes: List[str]):
        """è®¾ç½®è¦è·å–æ•°æ®çš„åŸºé‡‘ä»£ç åˆ—è¡¨"""
        self.fund_codes = codes
        logger.info(f"ğŸ“Š å·²è®¾ç½®åŸºé‡‘ä»£ç : {codes}")
    
    def fetch_fund_data(self, fund_code: str, 
                       start_date: Optional[str] = None, 
                       end_date: Optional[str] = None,
                       include_asset_size: bool = False) -> Optional[pd.DataFrame]:
        """
        è·å–å•ä¸ªåŸºé‡‘çš„æ•°æ®
        
        Args:
            fund_code: åŸºé‡‘ä»£ç ï¼ˆå¯ä»¥æ˜¯å¸¦æˆ–ä¸å¸¦.OFåç¼€çš„æ ¼å¼ï¼‰
            start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
            end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼YYYYMMDD
            include_asset_size: æ˜¯å¦åŒ…å«èµ„äº§è§„æ¨¡æ•°æ®
            
        Returns:
            DataFrameåŒ…å«åŸºé‡‘å†å²å‡€å€¼æ•°æ®ï¼Œå¤±è´¥åˆ™è¿”å›None
        """
        try:
            # å¤„ç†åŸºé‡‘ä»£ç æ ¼å¼
            original_fund_code = fund_code
            clean_fund_code = fund_code_manager.to_akshare_format(fund_code)
            
            logger.info(f"ğŸ” æ­£åœ¨è·å–åŸºé‡‘ {original_fund_code} (AKShareæ ¼å¼: {clean_fund_code}) çš„æ•°æ®...")
            
            # ä½¿ç”¨akshareè·å–åŸºé‡‘å‡€å€¼æ•°æ®
            # æ ¹æ®æ–‡æ¡£ï¼Œå‚æ•°åº”è¯¥æ˜¯symbolè€Œä¸æ˜¯fund
            fund_net_value_data = ak.fund_open_fund_info_em(symbol=clean_fund_code, indicator="å•ä½å‡€å€¼èµ°åŠ¿")
            
            if fund_net_value_data.empty:
                logger.warning(f"âš ï¸ åŸºé‡‘ {original_fund_code} æ²¡æœ‰è·å–åˆ°å‡€å€¼æ•°æ®")
                return None
            
            # é‡å‘½ååˆ—åä»¥ç¬¦åˆå†…éƒ¨æ ‡å‡†
            if 'å‡€å€¼æ—¥æœŸ' in fund_net_value_data.columns:
                fund_net_value_data.rename(columns={
                    'å‡€å€¼æ—¥æœŸ': 'date',
                    'å•ä½å‡€å€¼': 'nav',
                    'ç´¯è®¡å‡€å€¼': 'cumulative_nav',
                    'æ—¥å¢é•¿ç‡': 'daily_growth'
                }, inplace=True)
            elif 'date' in fund_net_value_data.columns:
                # å¦‚æœå·²ç»æ˜¯è‹±æ–‡åˆ—åï¼Œåˆ™ä¿æŒä¸å˜
                pass
            else:
                logger.error(f"âŒ æ— æ³•è¯†åˆ«åŸºé‡‘ {original_fund_code} çš„åˆ—åæ ¼å¼")
                return None
            
            # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯datetimeç±»å‹
            fund_net_value_data['date'] = pd.to_datetime(fund_net_value_data['date'])
            
            # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¥æœŸèŒƒå›´ï¼Œé»˜è®¤è·å–æœ€è¿‘ DEFAULT_FETCH_YEARS å¹´çš„æ•°æ®
            if not start_date:
                start_date = (datetime.now() - timedelta(days=365 * _FETCH_YEARS)).strftime('%Y%m%d')
            if not end_date:
                end_date = datetime.now().strftime('%Y%m%d')
                
            # ç­›é€‰æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„æ•°æ®
            fund_net_value_data = fund_net_value_data[
                (fund_net_value_data['date'] >= pd.to_datetime(start_date)) & 
                (fund_net_value_data['date'] <= pd.to_datetime(end_date))
            ].copy()
            
            if fund_net_value_data.empty:
                logger.warning(f"âš ï¸ åŸºé‡‘ {original_fund_code} åœ¨æŒ‡å®šæ—¥æœŸèŒƒå›´å†…æ²¡æœ‰æ•°æ®")
                return None
            
            # æŒ‰æ—¥æœŸæ’åº
            fund_net_value_data.sort_values(by='date', inplace=True)
            fund_net_value_data.reset_index(drop=True, inplace=True)
            
            # ç¡®ä¿ç´¯è®¡å‡€å€¼åˆ—å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨å•ä½å‡€å€¼
            if 'cumulative_nav' not in fund_net_value_data.columns or fund_net_value_data['cumulative_nav'].isna().all():
                logger.warning(f"âš ï¸ åŸºé‡‘ {original_fund_code} ç¼ºå°‘ç´¯è®¡å‡€å€¼æ•°æ®ï¼Œä½¿ç”¨å•ä½å‡€å€¼æ›¿ä»£")
                fund_net_value_data['cumulative_nav'] = fund_net_value_data['nav']
            
            # å¦‚æœè¯·æ±‚è·å–èµ„äº§è§„æ¨¡æ•°æ®ï¼Œåˆ™è·å–å¹¶åˆå¹¶
            if include_asset_size:
                asset_size_data = self._fetch_fund_asset_size(clean_fund_code)
                if asset_size_data is not None and not asset_size_data.empty:
                    # åˆå¹¶èµ„äº§è§„æ¨¡æ•°æ®åˆ°å‡€å€¼æ•°æ®
                    fund_net_value_data = self._merge_asset_size_data(fund_net_value_data, asset_size_data)
                else:
                    logger.warning(f"âš ï¸ åŸºé‡‘ {original_fund_code} æ— æ³•è·å–èµ„äº§è§„æ¨¡æ•°æ®ï¼Œå°†åœ¨å‡€å€¼æ•°æ®ä¸­è®¾ç½®é»˜è®¤å€¼")
                    # æ·»åŠ èµ„äº§è§„æ¨¡åˆ—å¹¶å¡«å……é»˜è®¤å€¼
                    fund_net_value_data['asset_size'] = None
            
            logger.info(f"âœ… åŸºé‡‘ {original_fund_code} æ•°æ®è·å–æˆåŠŸï¼Œå…± {len(fund_net_value_data)} æ¡è®°å½•")
            
            # æ·»åŠ åŸºé‡‘ä»£ç åˆ—ï¼ˆä½¿ç”¨åŸå§‹ä¼ å…¥æ ¼å¼ï¼‰
            fund_net_value_data['fund_id'] = original_fund_code
            
            return fund_net_value_data
            
        except Exception as e:
            logger.error(f"âŒ è·å–åŸºé‡‘ {fund_code} æ•°æ®å¤±è´¥: {e}")
            return None
    
    def _fetch_fund_asset_size(self, fund_code: str) -> Optional[pd.DataFrame]:
        """
        è·å–åŸºé‡‘çš„èµ„äº§è§„æ¨¡æ•°æ®
        
        Args:
            fund_code: åŸºé‡‘ä»£ç ï¼ˆAKShareæ ¼å¼ï¼‰
            
        Returns:
            DataFrameåŒ…å«èµ„äº§è§„æ¨¡æ•°æ®ï¼ŒåŒ…å«'date'å’Œ'asset_size'åˆ—
        """
        try:
            logger.info(f"ğŸ“Š æ­£åœ¨è·å–åŸºé‡‘ {fund_code} çš„èµ„äº§è§„æ¨¡æ•°æ®...")
            
            # å°è¯•è·å–åŸºé‡‘è§„æ¨¡æ•°æ®ï¼ˆé€šå¸¸ä¸ºå­£åº¦æ•°æ®ï¼‰
            # ä½¿ç”¨ ak.fund_fund_info_em è·å–åŸºé‡‘åŸºæœ¬ä¿¡æ¯ï¼Œå…¶ä¸­åŒ…å«èµ„äº§è§„æ¨¡
            fund_info = ak.fund_fund_info_em(symbol=fund_code)
            
            if fund_info.empty:
                logger.warning(f"âš ï¸ åŸºé‡‘ {fund_code} æ²¡æœ‰è·å–åˆ°èµ„äº§è§„æ¨¡æ•°æ®")
                return None
            
            # æŸ¥æ‰¾åŒ…å«èµ„äº§è§„æ¨¡çš„åˆ—
            asset_size_col = None
            for col in fund_info.columns:
                if 'è§„æ¨¡' in col or 'asset' in col.lower() or 'size' in col.lower():
                    asset_size_col = col
                    break
            
            if asset_size_col is None:
                logger.warning(f"âš ï¸ åŸºé‡‘ {fund_code} çš„èµ„äº§è§„æ¨¡åˆ—æœªæ‰¾åˆ°")
                return None
            
            # æå–èµ„äº§è§„æ¨¡æ•°æ®
            asset_size_data = fund_info[['å‡€å€¼æ—¥æœŸ', asset_size_col]].copy()
            asset_size_data.rename(columns={
                'å‡€å€¼æ—¥æœŸ': 'date',
                asset_size_col: 'asset_size'
            }, inplace=True)
            
            # æ¸…ç†èµ„äº§è§„æ¨¡æ•°æ®ï¼Œå»é™¤å•ä½å¹¶è½¬æ¢ä¸ºæ•°å€¼
            asset_size_data['date'] = pd.to_datetime(asset_size_data['date'])
            
            # è½¬æ¢èµ„äº§è§„æ¨¡ä¸ºæ•°å€¼ï¼ˆä¾‹å¦‚ï¼šå°†"123.45äº¿å…ƒ"è½¬æ¢ä¸º123.45ï¼‰
            def convert_asset_size(value):
                if pd.isna(value):
                    return None
                # ç§»é™¤å•ä½å¹¶è½¬æ¢ä¸ºæµ®ç‚¹æ•°
                try:
                    # å°è¯•ç›´æ¥è½¬æ¢æ•°å­—
                    return float(value)
                except:
                    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•æå–æ•°å­—éƒ¨åˆ†
                    import re
                    match = re.search(r'([\d\.]+)', str(value))
                    if match:
                        return float(match.group(1))
                    return None
            
            asset_size_data['asset_size'] = asset_size_data['asset_size'].apply(convert_asset_size)
            
            # æŒ‰æ—¥æœŸæ’åº
            asset_size_data.sort_values(by='date', inplace=True)
            asset_size_data.reset_index(drop=True, inplace=True)
            
            logger.info(f"âœ… åŸºé‡‘ {fund_code} èµ„äº§è§„æ¨¡æ•°æ®è·å–æˆåŠŸï¼Œå…± {len(asset_size_data)} æ¡è®°å½•")
            return asset_size_data
            
        except Exception as e:
            logger.warning(f"âš ï¸ è·å–åŸºé‡‘ {fund_code} èµ„äº§è§„æ¨¡æ•°æ®å¤±è´¥: {e}")
            # å°è¯•ä½¿ç”¨å…¶ä»–æ¥å£è·å–èµ„äº§è§„æ¨¡æ•°æ®
            try:
                # ä½¿ç”¨åŸºé‡‘åŸºæœ¬ä¿¡æ¯æ¥å£
                fund_basic_info = ak.fund_name_em()
                fund_info = fund_basic_info[fund_basic_info['åŸºé‡‘ä»£ç '] == fund_code]
                
                if not fund_info.empty:
                    # æŸ¥æ‰¾èµ„äº§è§„æ¨¡ç›¸å…³å­—æ®µ
                    for col in ['è§„æ¨¡', 'æœ€æ–°è§„æ¨¡', 'èµ„äº§è§„æ¨¡']:
                        if col in fund_info.columns:
                            asset_size = fund_info.iloc[0][col]
                            if not pd.isna(asset_size):
                                # åˆ›å»ºä¸€ä¸ªåŒ…å«å½“å‰æ—¥æœŸçš„èµ„äº§è§„æ¨¡æ•°æ®
                                today = datetime.now().strftime('%Y-%m-%d')
                                asset_size_data = pd.DataFrame({
                                    'date': [pd.to_datetime(today)],
                                    'asset_size': [convert_asset_size(asset_size)]
                                })
                                logger.info(f"âœ… åŸºé‡‘ {fund_code} ä»åŸºæœ¬ä¿¡æ¯è·å–åˆ°èµ„äº§è§„æ¨¡: {asset_size}")
                                return asset_size_data
            except Exception as inner_e:
                logger.debug(f"ä»å¤‡ç”¨æ¥å£è·å–èµ„äº§è§„æ¨¡ä¹Ÿå¤±è´¥: {inner_e}")
            
            return None
    
    def _merge_asset_size_data(self, nav_data: pd.DataFrame, asset_size_data: pd.DataFrame) -> pd.DataFrame:
        """
        å°†èµ„äº§è§„æ¨¡æ•°æ®åˆå¹¶åˆ°å‡€å€¼æ•°æ®ä¸­
        
        Args:
            nav_data: å‡€å€¼æ•°æ®DataFrame
            asset_size_data: èµ„äº§è§„æ¨¡æ•°æ®DataFrame
            
        Returns:
            åˆå¹¶åçš„DataFrame
        """
        # ç¡®ä¿ä¸¤ä¸ªDataFrameéƒ½æœ‰dateåˆ—ä¸”ä¸ºdatetimeç±»å‹
        nav_data = nav_data.copy()
        
        if asset_size_data.empty:
            nav_data['asset_size'] = None
            return nav_data
        
        # ç”±äºèµ„äº§è§„æ¨¡æ•°æ®æ˜¯å­£åº¦æ•°æ®ï¼Œè€Œå‡€å€¼æ•°æ®æ˜¯æ—¥æ•°æ®ï¼Œ
        # æˆ‘ä»¬éœ€è¦ä½¿ç”¨å‰å‘å¡«å……çš„æ–¹æ³•å°†å­£åº¦æ•°æ®æ‰©å±•åˆ°æ—¥æ•°æ®
        merged_data = nav_data.merge(asset_size_data, on='date', how='left')
        
        # å¯¹èµ„äº§è§„æ¨¡åˆ—è¿›è¡Œå‰å‘å¡«å……ï¼ˆä½¿ç”¨æœ€è¿‘å·²çŸ¥çš„èµ„äº§è§„æ¨¡æ•°æ®ï¼‰
        merged_data['asset_size'] = merged_data['asset_size'].ffill()
        
        # å¦‚æœä»ç„¶æœ‰ç¼ºå¤±å€¼ï¼Œä½¿ç”¨åå‘å¡«å……ï¼ˆä½¿ç”¨æœªæ¥çš„æ•°æ®å¡«å……è¿‡å»ï¼‰
        merged_data['asset_size'] = merged_data['asset_size'].bfill()
        
        # å¦‚æœè¿˜æœ‰ç¼ºå¤±å€¼ï¼Œè®¾ç½®ä¸ºNone
        merged_data['asset_size'] = merged_data['asset_size'].where(
            pd.notnull(merged_data['asset_size']), None
        )
        
        return merged_data
    
    def fetch_all_funds_data(self, fund_codes: List[str], include_asset_size: bool = False) -> Dict[str, pd.DataFrame]:
        """
        è·å–å¤šä¸ªåŸºé‡‘çš„æ•°æ®
        
        Args:
            fund_codes: åŸºé‡‘ä»£ç åˆ—è¡¨ï¼ˆå¯ä»¥æ˜¯å¸¦æˆ–ä¸å¸¦.OFåç¼€çš„æ ¼å¼ï¼‰
            include_asset_size: æ˜¯å¦åŒ…å«èµ„äº§è§„æ¨¡æ•°æ®
            
        Returns:
            å­—å…¸ï¼Œé”®ä¸ºåŸºé‡‘ä»£ç ï¼Œå€¼ä¸ºå¯¹åº”çš„DataFrame
        """
        results = {}
        
        for fund_code in fund_codes:
            logger.info(f"ğŸ“Š æ­£åœ¨è·å–åŸºé‡‘ {fund_code} çš„æ•°æ®...")
            
            # è·å–å•ä¸ªåŸºé‡‘æ•°æ®
            fund_data = self.fetch_fund_data(fund_code, include_asset_size=include_asset_size)
            
            if fund_data is not None:
                results[fund_code] = fund_data
                
                # æ·»åŠ åˆ°ç¼“å­˜
                self.data_cache[fund_code] = fund_data
            else:
                logger.warning(f"âš ï¸ åŸºé‡‘ {fund_code} æ•°æ®è·å–å¤±è´¥")
            
            # æ·»åŠ å»¶æ—¶é¿å…è¿‡äºé¢‘ç¹çš„APIè°ƒç”¨
            time.sleep(0.5)
        
        logger.info(f"âœ… å…±æˆåŠŸè·å– {len(results)} åªåŸºé‡‘çš„æ•°æ®")
        return results
    
    def get_fund_info(self, fund_code: str) -> dict:
        """
        è·å–å•åªåŸºé‡‘çš„åŸºæœ¬ä¿¡æ¯
        
        Args:
            fund_code: åŸºé‡‘ä»£ç ï¼ˆå¯ä»¥æ˜¯å¸¦æˆ–ä¸å¸¦.OFåç¼€çš„æ ¼å¼ï¼‰
            
        Returns:
            åŸºé‡‘åŸºæœ¬ä¿¡æ¯å­—å…¸
        """
        try:
            # å¤„ç†åŸºé‡‘ä»£ç æ ¼å¼
            original_fund_code = fund_code
            clean_fund_code = fund_code_manager.to_akshare_format(fund_code)
            
            logger.info(f"ğŸ” æ­£åœ¨è·å–åŸºé‡‘ {original_fund_code} çš„åŸºæœ¬ä¿¡æ¯...")
            
            # ä½¿ç”¨æ­£ç¡®çš„æ¥å£è·å–åŸºé‡‘åŸºæœ¬ä¿¡æ¯
            fund_info_df = ak.fund_name_em()
            
            # è¿‡æ»¤æŒ‡å®šåŸºé‡‘ä»£ç çš„æ•°æ®
            fund_info = fund_info_df[fund_info_df['åŸºé‡‘ä»£ç '] == clean_fund_code]
            
            if fund_info.empty:
                logger.warning(f"æœªæ‰¾åˆ°åŸºé‡‘ä»£ç  {original_fund_code} (AKShareæ ¼å¼: {clean_fund_code}) çš„åŸºæœ¬ä¿¡æ¯")
                return {}
                
            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            info_dict = fund_info.iloc[0].to_dict()
            
            # æå–å…³é”®å­—æ®µ
            result = {
                'fund_id': original_fund_code,  # ä¿æŒåŸå§‹ä¼ å…¥æ ¼å¼
                'name': info_dict.get('åŸºé‡‘ç®€ç§°', ''),
                'type': info_dict.get('åŸºé‡‘ç±»å‹', ''),
                'pinyin_short': info_dict.get('æ‹¼éŸ³ç¼©å†™', ''),
                'pinyin_full': info_dict.get('æ‹¼éŸ³å…¨ç§°', '')
            }
            
            # å°è¯•è·å–èµ„äº§è§„æ¨¡ä¿¡æ¯
            for asset_key in ['è§„æ¨¡', 'æœ€æ–°è§„æ¨¡', 'èµ„äº§è§„æ¨¡']:
                if asset_key in info_dict:
                    result['asset_size'] = info_dict.get(asset_key)
                    break
            
            logger.info(f"âœ… æˆåŠŸè·å–åŸºé‡‘ {original_fund_code} çš„åŸºæœ¬ä¿¡æ¯")
            return result
            
        except Exception as e:
            logger.error(f"âŒ è·å–åŸºé‡‘ {fund_code} åŸºæœ¬ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    fetcher = FundDataFetcher()
    test_codes = SAMPLE_FUND_CODES[:2]  # åªæµ‹è¯•å‰ä¸¤ä¸ªåŸºé‡‘
    
    print("æµ‹è¯•åŸºé‡‘æ•°æ®è·å–ï¼ˆåŒ…å«èµ„äº§è§„æ¨¡ï¼‰:")
    print("="*60)
    
    # æµ‹è¯•è·å–åŸºé‡‘æ•°æ®ï¼ˆåŒ…å«èµ„äº§è§„æ¨¡ï¼‰
    results = fetcher.fetch_all_funds_data(test_codes, include_asset_size=True)
    
    for code, data in results.items():
        print(f"\nåŸºé‡‘ {code} çš„å‰5æ¡æ•°æ®:")
        print(data[['date', 'nav', 'cumulative_nav', 'asset_size']].head() if 'asset_size' in data.columns else data.head())
        
        # å¦‚æœæœ‰èµ„äº§è§„æ¨¡æ•°æ®ï¼Œæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        if 'asset_size' in data.columns:
            asset_stats = data['asset_size'].describe()
            print(f"èµ„äº§è§„æ¨¡ç»Ÿè®¡: éç©ºå€¼ {data['asset_size'].count()} æ¡ï¼Œå¹³å‡å€¼ {asset_stats.get('mean', 'N/A'):.2f}")
    
    # æµ‹è¯•è·å–åŸºé‡‘åŸºæœ¬ä¿¡æ¯
    print("\n" + "="*60)
    print("æµ‹è¯•è·å–åŸºé‡‘åŸºæœ¬ä¿¡æ¯:")
    for code in test_codes:
        fund_info = fetcher.get_fund_info(code)
        print(f"\nåŸºé‡‘ {code} çš„åŸºæœ¬ä¿¡æ¯:")
        for key, value in fund_info.items():
            print(f"  {key}: {value}")