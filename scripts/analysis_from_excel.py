#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
analysis_from_excel.py - ä»Excelæ–‡ä»¶ç›´æ¥è¿›è¡Œåˆ†æ

åŠŸèƒ½ï¼š
1. ä»Excelè¯»å–åŸºé‡‘æ•°æ®
2. ç›´æ¥è°ƒç”¨åˆ†æå‡½æ•°è®¡ç®—æŒ‡æ ‡
3. ç”ŸæˆæŠ¥å‘Šå’Œå›¾è¡¨
4. ä¸å†™å…¥ä¸»æ•°æ®åº“ï¼ˆå¯é€‰ï¼‰

ä½¿ç”¨ç¤ºä¾‹ï¼š
  æµ‹è¯•æ–‡ä»¶åœ¨fund_analysis_project\sample\fund_sample.xlsx
  python scripts/analysis_from_excel.py --input sample/fund_sample.xlsx --fund-code 000001.OF
  python scripts/analysis_from_excel.py --input data/export.xlsx --sheet daily_nav --write-db
"""

import sys
import os
import argparse
import logging
from pathlib import Path
import pandas as pd
import numpy as np
from datetime import datetime

# ä¿è¯è„šæœ¬ç‹¬ç«‹è¿è¡Œæ—¶èƒ½æ‰¾åˆ°é¡¹ç›®å†…æ¨¡å—
PROJECT_ROOT = Path(__file__).resolve().parent.parent
SRC_DIR = PROJECT_ROOT / "src"
for candidate in (PROJECT_ROOT, SRC_DIR):
    if str(candidate) not in sys.path:
        sys.path.insert(0, str(candidate))

from src.utils.runtime_env import add_project_paths

# ç»Ÿä¸€å¤„ç†å†»ç»“/æ™®é€šç¯å¢ƒä¸‹çš„è·¯å¾„ä¸å¯¼å…¥
REPO_ROOT, STORAGE_ROOT = add_project_paths()

from src.analysis.performance import PerformanceAnalyzer
from src.analysis.holding_simulation import HoldingSimulation
from src.analysis.visualization import FundVisualizer
from src.utils.database import fund_db
from src.utils.output_manager import get_output_manager
import config

# è¾“å‡ºç®¡ç†å™¨ï¼ˆç”¨äºæ—¥å¿—ä¸æ–‡ä»¶è½ç›˜ï¼‰
OUTPUT_MANAGER = get_output_manager('excel_analysis', base_dir=config.REPORTS_DIR, use_timestamp=True)

# é…ç½®æ—¥å¿—
log_file = OUTPUT_MANAGER.get_path('logs', 'excel_analysis.log')
log_file.parent.mkdir(parents=True, exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(str(log_file), encoding='utf-8')
    ],
    force=True
)
logger = logging.getLogger(__name__)


def summarize_holding_results(holding_results):
    """æå–æŒæœ‰æœŸç»Ÿè®¡ç”¨äºå±•ç¤ºå’ŒæŠ¥å‘Š"""
    summary = {}
    for holding_days, results_df in holding_results.items():
        if results_df is not None and not results_df.empty:
            summary[holding_days] = {
                'count': len(results_df),
                'mean_return': results_df['holding_return'].mean(),
                'win_rate': (results_df['holding_return'] > 0).mean()
            }
    return summary


def generate_markdown_report(performance_records, holding_summaries, input_path,
                             target_paths, excel_output=None):
    """ç”ŸæˆMarkdownæŠ¥å‘Šå†…å®¹å¹¶å†™å…¥æŒ‡å®šè·¯å¾„"""

    def _format_pct(value):
        return f"{value:.2%}" if pd.notna(value) else "N/A"

    def _format_float(value, digits=4):
        return f"{value:.{digits}f}" if pd.notna(value) else "N/A"

    now_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    lines = [
        "# Excelæ•°æ®åˆ†ææŠ¥å‘Š",
        "",
        f"- ç”Ÿæˆæ—¶é—´: {now_str}",
        f"- è¾“å…¥æ–‡ä»¶: {input_path}",
        f"- ç»©æ•ˆç»“æœæ–‡ä»¶: {excel_output or 'æœªç”Ÿæˆ'}"
    ]

    lines.append("\n## ç»©æ•ˆæ¦‚è§ˆ")
    if performance_records is not None and len(performance_records) > 0:
        lines.append("| åŸºé‡‘ä»£ç  | æ€»æ”¶ç›Šç‡ | å¹´åŒ–æ”¶ç›Šç‡ | æœ€å¤§å›æ’¤ | å¤æ™®æ¯”ç‡ |")
        lines.append("| --- | --- | --- | --- | --- |")
        for record in performance_records:
            lines.append(
                f"| {record['fund_id']} | {_format_pct(record['total_return'])} | "
                f"{_format_pct(record['annual_return'])} | {_format_pct(record['max_drawdown'])} | "
                f"{_format_float(record.get('sharpe_ratio'))} |"
            )
    else:
        lines.append("æš‚æ— ç»©æ•ˆæ•°æ®ã€‚")

    lines.append("\n## æŒæœ‰æœŸç»Ÿè®¡")
    if holding_summaries:
        for fund_id, fund_summary in holding_summaries.items():
            lines.append(f"### {fund_id}")
            if fund_summary:
                lines.append("| æŒæœ‰æœŸ(å¤©) | æ ·æœ¬æ•° | å¹³å‡æ”¶ç›Šç‡ | èƒœç‡ |")
                lines.append("| --- | --- | --- | --- |")
                for holding_days in sorted(fund_summary.keys()):
                    stats = fund_summary[holding_days]
                    lines.append(
                        f"| {holding_days} | {stats['count']} | "
                        f"{_format_pct(stats['mean_return'])} | {_format_pct(stats['win_rate'])} |"
                    )
            else:
                lines.append("æš‚æ— æŒæœ‰æœŸç»“æœã€‚")
    else:
        lines.append("æš‚æ— æŒæœ‰æœŸç»“æœã€‚")

    content = "\n".join(lines)
    for path in target_paths:
        path.parent.mkdir(parents=True, exist_ok=True)
        with open(path, 'w', encoding='utf-8') as f:
            f.write(content)
        logger.info(f"MarkdownæŠ¥å‘Šå·²ç”Ÿæˆ: {path}")


def read_excel_data(file_path, sheet_name=None, fund_code=None):
    """
    ä»Excelè¯»å–åŸºé‡‘æ•°æ®
    
    Excelæ ¼å¼è¦æ±‚ï¼š
    - åˆ—åå¿…é¡»åŒ…å«: date, nav (æˆ– cumulative_nav)
    - å¯é€‰åˆ—: fund_id, daily_growth, net_assets
    - dateåˆ—åº”ä¸ºæ—¥æœŸæ ¼å¼
    """
    try:
        print(f"ğŸ“– è¯»å–Excelæ–‡ä»¶: {file_path}")
        
        # è¯»å–Excel
        if sheet_name:
            df = pd.read_excel(file_path, sheet_name=sheet_name)
        else:
            # å°è¯•è¯»å–ç¬¬ä¸€ä¸ªsheet
            xl = pd.ExcelFile(file_path)
            df = xl.parse(xl.sheet_names[0])
        
        print(f"   åŸå§‹æ•°æ®å½¢çŠ¶: {df.shape}")
        print(f"   åˆ—å: {list(df.columns)}")
        
        # æ ‡å‡†åŒ–åˆ—åï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
        column_mapping = {}
        for col in df.columns:
            col_lower = str(col).lower().strip()
            if col_lower in ['date', 'æ—¥æœŸ', 'äº¤æ˜“æ—¥æœŸ']:
                column_mapping[col] = 'date'
            elif col_lower in ['nav', 'å•ä½å‡€å€¼', 'å‡€å€¼']:
                column_mapping[col] = 'nav'
            elif col_lower in ['cumulative_nav', 'ç´¯è®¡å‡€å€¼', 'ç´¯è®¡å‡€å€¼']:
                column_mapping[col] = 'cumulative_nav'
            elif col_lower in ['fund_id', 'åŸºé‡‘ä»£ç ', 'ä»£ç ']:
                column_mapping[col] = 'fund_id'
            elif col_lower in ['daily_growth', 'æ—¥å¢é•¿ç‡', 'å¢é•¿ç‡']:
                column_mapping[col] = 'daily_growth'
        
        if column_mapping:
            df = df.rename(columns=column_mapping)
            print(f"   æ ‡å‡†åŒ–ååˆ—å: {list(df.columns)}")
        
        # æ£€æŸ¥å¿…è¦åˆ—
        if 'date' not in df.columns:
            raise ValueError("Excelä¸­å¿…é¡»åŒ…å«dateåˆ—ï¼ˆæˆ–æ—¥æœŸåˆ—ï¼‰")
        
        if 'nav' not in df.columns and 'cumulative_nav' not in df.columns:
            raise ValueError("Excelä¸­å¿…é¡»åŒ…å«navæˆ–cumulative_navåˆ—")
        
        # è½¬æ¢æ—¥æœŸåˆ—
        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        df = df.dropna(subset=['date'])
        
        # è®¾ç½®åŸºé‡‘ä»£ç 
        if 'fund_id' in df.columns:
            if df['fund_id'].isna().all():
                df['fund_id'] = fund_code or 'EXCEL_FUND'
        else:
            df['fund_id'] = fund_code or 'EXCEL_FUND'
        
        # æŒ‰æ—¥æœŸæ’åº
        df = df.sort_values('date')
        
        # å¤„ç†å‡€å€¼æ•°æ®
        if 'cumulative_nav' not in df.columns and 'nav' in df.columns:
            # å¦‚æœæ²¡æœ‰ç´¯è®¡å‡€å€¼ï¼Œä½¿ç”¨å•ä½å‡€å€¼
            df['cumulative_nav'] = df['nav']
            print("   âš ï¸  ä½¿ç”¨å•ä½å‡€å€¼ä½œä¸ºç´¯è®¡å‡€å€¼")
        elif 'nav' not in df.columns and 'cumulative_nav' in df.columns:
            # å¦‚æœæ²¡æœ‰å•ä½å‡€å€¼ï¼Œä½¿ç”¨ç´¯è®¡å‡€å€¼
            df['nav'] = df['cumulative_nav']
            print("   âš ï¸  ä½¿ç”¨ç´¯è®¡å‡€å€¼ä½œä¸ºå•ä½å‡€å€¼")
        
        print(f"   å¤„ç†åæ•°æ®: {len(df)} è¡Œï¼Œæ—¶é—´èŒƒå›´: {df['date'].min()} åˆ° {df['date'].max()}")
        
        return df
        
    except Exception as e:
        logger.error(f"è¯»å–Excelæ–‡ä»¶å¤±è´¥: {e}")
        raise


def analyze_excel_fund(df, fund_code, output_dir, analyzer, visualizer, periods, output_manager=None):
    """åˆ†æå•ä¸ªExcelåŸºé‡‘"""
    try:
        print(f"\nğŸ” åˆ†æåŸºé‡‘: {fund_code}")
        
        # æå–å‡€å€¼åºåˆ—
        if 'cumulative_nav' in df.columns and not df['cumulative_nav'].isna().all():
            nav_series = df.set_index('date')['cumulative_nav'].dropna()
            nav_type = 'cumulative'
        else:
            nav_series = df.set_index('date')['nav'].dropna()
            nav_type = 'nav'
        
        print(f"   å‡€å€¼ç±»å‹: {nav_type}, æ•°æ®ç‚¹æ•°: {len(nav_series)}")
        
        if len(nav_series) < 2:
            print(f"   âœ— æ•°æ®ä¸è¶³ï¼Œè‡³å°‘éœ€è¦2ä¸ªæ•°æ®ç‚¹")
            return None
        
        # è®¡ç®—ç»©æ•ˆæŒ‡æ ‡
        print(f"   ğŸ“Š è®¡ç®—ç»©æ•ˆæŒ‡æ ‡...")
        total_return = analyzer.calculate_total_return(nav_series)
        annual_return = analyzer.calculate_annual_return(nav_series)
        annual_volatility = analyzer.calculate_annual_volatility(nav_series)
        max_drawdown, start_date, end_date = analyzer.calculate_max_drawdown(nav_series)
        sharpe_ratio = analyzer.calculate_sharpe_ratio(nav_series)
        calmar_ratio = analyzer.calculate_calmar_ratio(nav_series)
        
        performance = {
            'fund_id': fund_code,
            'total_return': total_return,
            'annual_return': annual_return,
            'annual_volatility': annual_volatility,
            'max_drawdown': max_drawdown,
            'max_drawdown_start': start_date,
            'max_drawdown_end': end_date,
            'sharpe_ratio': sharpe_ratio,
            'calmar_ratio': calmar_ratio,
            'start_date': nav_series.index[0],
            'end_date': nav_series.index[-1],
            'periods': len(nav_series),
            'data_source': 'excel'
        }
        
        print(f"   æ€»æ”¶ç›Šç‡: {total_return:.2%}")
        print(f"   å¹´åŒ–æ”¶ç›Šç‡: {annual_return:.2%}")
        print(f"   æœ€å¤§å›æ’¤: {max_drawdown:.2%}")
        print(f"   å¤æ™®æ¯”ç‡: {sharpe_ratio:.4f}")
        
        return performance, nav_series
        
    except Exception as e:
        logger.error(f"åˆ†æåŸºé‡‘ {fund_code} å¤±è´¥: {e}")
        return None, None


def _fund_daily_data_exists(fund_code: str) -> bool:
    """æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦å·²æœ‰è¯¥åŸºé‡‘çš„æ—¥é¢‘æ•°æ®ã€‚"""
    try:
        conn = fund_db.get_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT COUNT(1) FROM fund_daily_data WHERE fund_id = ?", (fund_code,))
        count = cursor.fetchone()[0]
        conn.close()
        return count > 0
    except Exception:
        return False


def _insert_temp_fund_data(fund_code: str, nav_series: pd.Series) -> bool:
    """å°†Excelå‡€å€¼åºåˆ—ä¸´æ—¶å†™å…¥æ•°æ®åº“ï¼Œç”¨äºè¯¦ç»†è¡¨æ ¼ç”Ÿæˆã€‚"""
    try:
        fund_info = {
            'fund_id': fund_code,
            'name': f"Excelå¯¼å…¥-{fund_code}",
            'type': 'excel_import',
            'inception_date': nav_series.index[0].strftime('%Y-%m-%d')
        }
        fund_db.insert_fund_info(fund_info)

        daily_data = pd.DataFrame({
            'date': nav_series.index,
            'nav': nav_series.values,
            'cumulative_nav': nav_series.values
        })
        daily_data['daily_growth'] = daily_data['nav'].pct_change() * 100
        fund_db.insert_fund_daily_data(fund_code, daily_data)
        return True
    except Exception as e:
        logger.error(f"ä¸´æ—¶å†™å…¥åŸºé‡‘æ•°æ®å¤±è´¥: {e}")
        return False


def _cleanup_temp_fund_data(fund_code: str) -> None:
    """æ¸…ç†ä¸´æ—¶å†™å…¥çš„åŸºé‡‘æ•°æ®ã€‚"""
    try:
        conn = fund_db.get_connection()
        cursor = conn.cursor()
        cursor.execute("DELETE FROM fund_daily_data WHERE fund_id = ?", (fund_code,))
        cursor.execute("DELETE FROM funds WHERE fund_id = ?", (fund_code,))
        conn.commit()
        conn.close()
    except Exception as e:
        logger.warning(f"æ¸…ç†ä¸´æ—¶åŸºé‡‘æ•°æ®å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ä»Excelæ–‡ä»¶ç›´æ¥è¿›è¡Œåˆ†æ')
    
    # è¾“å…¥å‚æ•°
    parser.add_argument('--input', required=True, help='Excelæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--sheet', help='å·¥ä½œè¡¨åç§°ï¼ˆé»˜è®¤ï¼šç¬¬ä¸€ä¸ªå·¥ä½œè¡¨ï¼‰')
    parser.add_argument('--fund-code', help='åŸºé‡‘ä»£ç ï¼ˆå¦‚æœExcelä¸­æ²¡æœ‰fund_idåˆ—ï¼‰')
    
    # åˆ†æå‚æ•°
    parser.add_argument('--periods', nargs='+', type=int, default=config.HOLDING_PERIODS,
                       help='æŒæœ‰æœŸåˆ—è¡¨ï¼ˆé»˜è®¤ï¼š30 60 90 180 360ï¼‰')
    
    # è¾“å‡ºå‚æ•°
    parser.add_argument('--output-dir', default='reports/excel_analysis',
                       help='è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼šreports/excel_analysisï¼‰')
    parser.add_argument('--write-db', action='store_true',
                       help='å°†æ•°æ®å†™å…¥ä¸»æ•°æ®åº“ï¼ˆé»˜è®¤ï¼šä¸å†™å…¥ï¼‰')
    parser.add_argument('--no-detailed-excel', action='store_true',
                       help='ä¸ç”Ÿæˆè¯¦ç»†ç»©æ•ˆè¡¨æ ¼ï¼ˆäº§å“åŠåŸºå‡†æ”¶ç›Šç‡/å‘¨æ”¶ç›Šç‡æ›²çº¿/æœˆåº¦æ”¶ç›Šç‡ï¼‰')
    parser.add_argument('--verbose', action='store_true',
                       help='æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–è¾“å‡ºç®¡ç†å™¨
    output_manager = OUTPUT_MANAGER
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logger.setLevel(logging.DEBUG)
    
    print("ğŸš€ å¼€å§‹Excelæ•°æ®åˆ†æ")
    print("=" * 60)
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    input_path = Path(args.input)
    if not input_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        return 1
    
    # ä½¿ç”¨è¾“å‡ºç®¡ç†å™¨åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = output_manager.get_path('base')
    excel_output_path = None
    
    try:
        # 1. è¯»å–Excelæ•°æ®
        df = read_excel_data(args.input, args.sheet, args.fund_code)
        
        # 2. åˆå§‹åŒ–åˆ†æå™¨
        analyzer = PerformanceAnalyzer(
            risk_free_rate=config.RISK_FREE_RATE,
            trading_days=config.TRADING_DAYS
        )
        
        simulator = HoldingSimulation(
            risk_free_rate=config.RISK_FREE_RATE,
            trading_days=config.TRADING_DAYS
        )
        
        # ä½¿ç”¨ excel_analysis è¾“å‡ºç®¡ç†å™¨åˆ›å»ºå¯è§†åŒ–å™¨ï¼ˆæœ¬è„šæœ¬ä¸“å±ç›®å½•ï¼‰
        visualizer = FundVisualizer(output_dir=output_dir, output_manager=OUTPUT_MANAGER)
        
        # 3. æŒ‰åŸºé‡‘åˆ†ç»„åˆ†æ
        all_performance = []
        all_holding_results = []
        holding_summaries = {}
        
        if 'fund_id' in df.columns:
            fund_codes = df['fund_id'].unique()
            print(f"\nğŸ“Š å‘ç° {len(fund_codes)} åªåŸºé‡‘: {fund_codes}")
        else:
            fund_codes = [args.fund_code or 'EXCEL_FUND']
        
        for fund_code in fund_codes:
            # ç­›é€‰è¯¥åŸºé‡‘çš„æ•°æ®
            fund_df = df[df['fund_id'] == fund_code].copy() if len(fund_codes) > 1 else df
            
            # åˆ†æç»©æ•ˆ
            result = analyze_excel_fund(
                fund_df, fund_code, output_dir, analyzer, visualizer, args.periods, output_manager
            )
            
            if result is None:
                continue
                
            performance, nav_series = result
            all_performance.append(performance)
            holding_summaries[fund_code] = {}

            # ç”Ÿæˆè¯¦ç»†ç»©æ•ˆè¡¨æ ¼ï¼ˆä½¿ç”¨ä¸ main ç›¸åŒçš„é€»è¾‘ï¼‰
            export_detailed = not args.no_detailed_excel
            temp_inserted = False
            if export_detailed:
                data_exists = _fund_daily_data_exists(fund_code)
                if not data_exists:
                    temp_inserted = _insert_temp_fund_data(fund_code, nav_series)

                try:
                    benchmark_id = config.get_fund_benchmark(fund_code) if hasattr(config, 'get_fund_benchmark') else config.DEFAULT_BENCHMARK
                    comparison_indices = config.get_fund_comparison_indices(fund_code) if hasattr(config, 'get_fund_comparison_indices') else None
                    detail_path = OUTPUT_MANAGER.get_path('excel_performance', f"{fund_code}_detailed_performance.xlsx")
                    ok = analyzer.save_detailed_performance_to_excel(
                        fund_code,
                        output_path=str(detail_path),
                        benchmark_id=benchmark_id,
                        comparison_indices=comparison_indices
                    )
                    if ok:
                        print(f"   âœ“ è¯¦ç»†ç»©æ•ˆå·²ä¿å­˜: {detail_path.name}")
                except Exception as e:
                    logger.error(f"ä¿å­˜åŸºé‡‘ {fund_code} è¯¦ç»†ç»©æ•ˆå¤±è´¥: {e}")
                finally:
                    if temp_inserted and not args.write_db:
                        _cleanup_temp_fund_data(fund_code)

            # åˆ†ææŒæœ‰æœŸï¼ˆå¦‚æœæ•°æ®è¶³å¤Ÿï¼‰
            if len(nav_series) > max(args.periods) + 10:
                print(f"   ğŸ“Š åˆ†ææŒæœ‰æœŸæ”¶ç›Š...")
                try:
                    holding_results = simulator.simulate_multiple_periods(
                        nav_series, args.periods
                    )

                    holding_summary = summarize_holding_results(holding_results)
                    holding_summaries[fund_code] = holding_summary
                    period_label = "/".join(str(p) for p in args.periods)
                    print(f"   æŒæœ‰æœŸç»Ÿè®¡ï¼ˆ{period_label}å¤©ï¼‰ï¼š")
                    for holding_days in args.periods:
                        stats = holding_summary.get(holding_days)
                        if stats:
                            print(f"     {holding_days}å¤©: å¹³å‡æ”¶ç›Š{stats['mean_return']:.2%}, èƒœç‡{stats['win_rate']:.2%}, æ ·æœ¬æ•°{stats['count']}")
                        else:
                            print(f"     {holding_days}å¤©: æ•°æ®ä¸è¶³")
                    
                    # ä½¿ç”¨æ–°çš„æ‰¹é‡ä¿å­˜æ–¹æ³•ï¼ˆé™æ€å›¾ä¿å­˜åˆ° excel_analysis ç»“æ„ï¼‰
                    visualizer.save_all_holding_plots({
                        'simulation_results': holding_results
                    }, fund_code, output_manager=OUTPUT_MANAGER)

                    # ç”Ÿæˆäº¤äº’å¼æŒæœ‰æœŸåˆ†å¸ƒ
                    if config.OUTPUT_HTML_HOLDING_DIST:
                        for holding_days in args.periods:
                            results_df = holding_results.get(
                                holding_days, pd.DataFrame(columns=['holding_return'])
                            )
                            benchmark_returns = {}
                            for benchmark_id in config.BENCHMARK_IDS:
                                if hasattr(config, 'normalize_index_code'):
                                    actual_code = config.normalize_index_code(benchmark_id)
                                else:
                                    actual_code = benchmark_id
                                benchmark_name = config.get_benchmark_display_name(benchmark_id)
                                returns = simulator.get_benchmark_returns(actual_code, holding_days)
                                if not returns.empty:
                                    benchmark_returns[benchmark_name] = returns
                            interactive_fig = visualizer.create_interactive_return_distribution(
                                results_df, holding_days, fund_code, benchmark_returns
                            )
                            if interactive_fig:
                                html_path = OUTPUT_MANAGER.get_path(
                                    'interactive', f"{fund_code}_æŒæœ‰æœŸ{holding_days}å¤©_äº¤äº’.html", fund_id=fund_code
                                )
                                interactive_fig.write_html(str(html_path))
                                print(f"     âœ“ äº¤äº’å›¾ {holding_days}å¤©: {html_path.name}")

                    # ä¿å­˜æ¯åªåŸºé‡‘çš„æŒæœ‰æœŸç»“æœåˆ° main ç»“æ„çš„ excel_holding
                    holding_analysis_dict = {
                        'simulation_results': holding_results,
                        'summary': holding_summary
                    }
                    holding_excel_path = OUTPUT_MANAGER.get_path('excel_holding', f'holding_analysis_{fund_code}.xlsx')
                    simulator.save_simulation_results(holding_analysis_dict, str(holding_excel_path))
                    print(f"   ğŸ’¾ æŒæœ‰æœŸç»“æœå·²ä¿å­˜: {holding_excel_path}")

                    all_holding_results.append({
                        'fund_id': fund_code,
                        'results': holding_results
                    })
                    
                except Exception as e:
                    logger.error(f"åˆ†ææŒæœ‰æœŸå¤±è´¥: {e}")
                    print(f"   âœ— æŒæœ‰æœŸåˆ†æå¤±è´¥: {e}")
            else:
                print(f"   âš ï¸ æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¦†ç›–æ‰€æœ‰æŒæœ‰æœŸï¼ˆéœ€è¦è¶…è¿‡ {max(args.periods) + 10} ä¸ªæ•°æ®ç‚¹ï¼‰")
                for holding_days in args.periods:
                    print(f"     {holding_days}å¤©: æ•°æ®ä¸è¶³")
            
            # ç”Ÿæˆå‡€å€¼æ›²çº¿å’Œå›æ’¤å›¾
            print(f"   ğŸ¨ ç”Ÿæˆå›¾è¡¨...")
            try:
                # å‡€å€¼æ›²çº¿ï¼ˆé™æ€ï¼‰
                visualizer.plot_nav_curve(nav_series, fund_code)

                # äº¤äº’å¼å‡€å€¼æ›²çº¿ï¼ˆä¸ main ç›¸åŒï¼‰
                if config.OUTPUT_HTML_NAV_CURVE:
                    interactive_nav = visualizer.create_interactive_nav_curve(nav_series, fund_code)
                    if interactive_nav:
                        html_path = OUTPUT_MANAGER.get_interactive_path(fund_code, 'nav_curve')
                        interactive_nav.write_html(str(html_path))
                        print(f"   âœ“ äº¤äº’å‡€å€¼æ›²çº¿: {html_path.name}")

                # å›æ’¤å›¾ï¼ˆé™æ€ï¼‰
                visualizer.plot_drawdown_chart(nav_series, fund_code)

                # äº¤äº’å¼å‡€å€¼+å›æ’¤å›¾
                if config.OUTPUT_HTML_NAV_DRAWDOWN:
                    interactive_drawdown = visualizer.create_interactive_chart(nav_series, fund_code)
                    if interactive_drawdown:
                        html_path = OUTPUT_MANAGER.get_interactive_path(fund_code, 'nav_drawdown')
                        interactive_drawdown.write_html(str(html_path))
                        print(f"   âœ“ äº¤äº’å‡€å€¼å›æ’¤å›¾: {html_path.name}")
                
                print(f"   âœ“ å›¾è¡¨ç”Ÿæˆå®Œæˆ")
                
            except Exception as e:
                logger.error(f"ç”Ÿæˆå›¾è¡¨å¤±è´¥: {e}")
                print(f"   âœ— å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
            
            # å†™å…¥æ•°æ®åº“ï¼ˆå¯é€‰ï¼‰
            if args.write_db:
                print(f"   ğŸ’¾ å†™å…¥æ•°æ®åº“...")
                try:
                    # ä¿å­˜åŸºé‡‘åŸºæœ¬ä¿¡æ¯ï¼ˆç®€åŒ–ï¼‰
                    fund_info = {
                        'fund_id': fund_code,
                        'name': f"Excelå¯¼å…¥-{fund_code}",
                        'type': 'excel_import',
                        'inception_date': nav_series.index[0].strftime('%Y-%m-%d')
                    }
                    fund_db.insert_fund_info(fund_info)
                    
                    # ä¿å­˜æ—¥é¢‘æ•°æ®
                    daily_data = pd.DataFrame({
                        'date': nav_series.index,
                        'nav': nav_series.values,
                        'cumulative_nav': nav_series.values
                    })
                    inserted = fund_db.insert_fund_daily_data(fund_code, daily_data)
                    
                    print(f"   âœ“ å†™å…¥æ•°æ®åº“å®Œæˆ: {inserted} æ¡è®°å½•")
                    
                except Exception as e:
                    logger.error(f"å†™å…¥æ•°æ®åº“å¤±è´¥: {e}")
                    print(f"   âœ— å†™å…¥æ•°æ®åº“å¤±è´¥: {e}")
        
        # 4. ä¿å­˜ç»©æ•ˆç»“æœï¼ˆä¸ main ä¸€è‡´ï¼Œè¾“å‡ºåˆ° reports/main/.../excel/performanceï¼‰
        if all_performance:
            print(f"\nğŸ’¾ ä¿å­˜åˆ†æç»“æœ...")
            
            performance_df = pd.DataFrame(all_performance)
            perf_path = OUTPUT_MANAGER.get_path('excel_performance', 'performance_summary.xlsx')
            excel_output_path = perf_path
            # ä½¿ç”¨ä¸ main ç›¸åŒçš„ä¿å­˜æ–¹æ³•ï¼ˆæŒ‡æ•°ä¸ºç©ºï¼‰
            analyzer.save_performance_to_excel(performance_df, pd.DataFrame(), str(perf_path))
            print(f"   ç»©æ•ˆç»“æœå·²ä¿å­˜: {perf_path}")
            
            # æ‰“å°æ±‡æ€»
            print(f"\nğŸ“‹ åˆ†ææ±‡æ€»:")
            print(f"   åˆ†æåŸºé‡‘æ•°: {len(all_performance)}")
            print(f"   æŒæœ‰æœŸåˆ†æ: {len(all_holding_results)}")
            print(f"   è¾“å‡ºç›®å½•: {output_dir.absolute()}")
        
        print("\n" + "=" * 60)
        print("âœ… Excelæ•°æ®åˆ†æå®Œæˆï¼")
        
        # è¾“å‡ºç›®å½•æ‘˜è¦
        output_manager.print_summary()

        report_targets = [
            OUTPUT_MANAGER.get_path('reports', 'excel_analysis_report.md')
        ]
        generate_markdown_report(
            all_performance,
            holding_summaries,
            str(input_path),
            report_targets,
            excel_output=str(excel_output_path) if excel_output_path else None
        )
        print(f"ğŸ“ MarkdownæŠ¥å‘Šå·²ä¿å­˜: {report_targets[0]}")
        
        return 0
        
    except Exception as e:
        logger.error(f"Excelåˆ†æå¤±è´¥: {e}")
        print(f"\nâŒ Excelåˆ†æå¤±è´¥: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())